# Results: Testing Prototype Intersection with XOR Classification

## Overview

This experiment investigates the hypothesis that neural networks, particularly those using Absolute Value (Abs) or ReLU activation functions, learn by positioning their internal decision boundaries (hyperplanes) relative to data prototypes rather than solely achieving linear separability. The classic XOR problem serves as a minimal, non-linearly separable task to test this idea. We train small neural networks with different activation functions (Abs, ReLU, Sigmoid) to classify the 4 XOR data points and analyze the geometry of their learned solutions.

The key outcomes to look for in these results are:

* Whether the learned hyperplanes in the first layer visually intersect or align with the XOR input points (prototypes).
* The classification accuracy achieved by each model architecture across multiple trials.
* Whether the ReLU-based models exhibit symmetric, mirrored weight pairs when successfully solving the task, potentially mimicking the Abs activation function's behavior.

---

## Experiment Description

The core task is to train simple neural network models to correctly classify the 4 points of the standard XOR problem.

* **Input:** 2-dimensional data vectors $x$ representing the 4 XOR points (`[[-1,-1], [1,-1], [-1,1], [1,1]]`).
* **Target Output:** The corresponding XOR class labels (`[0, 1, 1, 0]`).
* **Goal:** To train models to achieve perfect classification accuracy and, more importantly, to analyze the geometric arrangement of the learned hyperplanes in the first layer to determine if they align with the prototype intersection hypothesis.

---

## Model Architectures

Three simple two-layer model architectures (`XOR_Abs`, `XOR_ReLU`, `XOR_Sigmoid`) are implemented and compared, differing primarily in the activation function used after the first linear layer. All models take the 2D input $x$ and output 2D logits for classification.

1.  **Absolute Value Model (`XOR_Abs`)**
    * **Architecture:** `Linear(2 -> 1)` -> `Abs` -> `Linear(1 -> 2)`.
    * **Justification:** This architecture directly tests the hypothesis that a single neuron with Abs activation can solve XOR by placing its linear boundary ($w^T x + b = 0$) to intersect two diagonally opposite XOR points (e.g., `[-1,-1]` and `[1,1]`), effectively using the prototypes as anchors. The `Abs` function creates a V-shaped response centered on this boundary.

2.  **ReLU-based Model (`XOR_ReLU`)**
    * **Architecture:** `Linear(2 -> 2)` -> `ReLU` -> `Linear(2 -> 2)`.
    * **Justification:** This tests if two ReLU neurons can replicate the Abs behavior by learning mirrored weights ($w_1 \approx -w_2$), thereby creating the necessary V-shaped decision region through the combination $ReLU(w^T x + b) + ReLU(-w^T x - b') \approx |w^T x + b''|$. Successful solutions are expected to show symmetry and prototype intersection.

3.  **Sigmoid Model (`XOR_Sigmoid`)**
    * **Architecture:** `Linear(2 -> 2)` -> `Sigmoid` -> `Linear(2 -> 2)`.
    * **Justification:** This serves as a baseline using a traditional activation function. While Sigmoid can solve XOR, the hypothesis suggests its mechanism might still involve placing its activation boundaries (where activation is 0.5) relative to the prototypes, though perhaps less directly than Abs or ReLU. It uses 2 hidden neurons for structural comparison with `XOR_ReLU`.

---

## Training and Test Data

The dataset consists solely of the 4 standard XOR input points and their corresponding labels:
* Inputs $x$: `[[-1.0, -1.0], [ 1.0, -1.0], [-1.0, 1.0], [ 1.0, 1.0]]`
* Labels $y$: `[0, 1, 1, 0]`

This dataset is generated by the `create_xor_dataset` function in `xor_lib.py`. Given the extremely small size of the dataset, the same 4 points are used for both training and evaluation in every epoch and trial.

---

## Experimental Methodology

### Initialization

* **Weights:** Weights for the linear layers are initialized using standard practices appropriate for the activation functions: Kaiming Normal for ReLU and Abs layers, and Xavier Normal for Sigmoid layers.
* **Biases:** All biases in the first linear layer are initialized to zero. This encourages the initial hyperplanes to pass through the origin, which is the center of the XOR data points.

### Training Process

Each model was trained using the following procedure:

* **Optimizer:** Adam (`torch.optim.Adam`)
* **Learning Rate:** $1 \times 10^{-3}$
* **Adam Betas:** $(0.9, 0.99)$
* **Epochs:** 5000 (sufficient for convergence on this small dataset)
* **Loss Function:** Cross-Entropy Loss (`nn.CrossEntropyLoss`), calculated between the model's output logits and the target labels.
* **Device:** Training was performed on a CUDA-enabled GPU if available, otherwise on the CPU.
* **Data Handling:** Training utilized **full-batch gradient descent** (processing all 4 points in each step), as is standard for the XOR problem.

### Multiple Trials and Data Collection

The entire training process was repeated **20 times independently** for each model architecture (`XOR_Abs`, `XOR_ReLU`, `XOR_Sigmoid`). After training, the final model state, classification accuracy on the 4 XOR points, and training loss history were collected for each trial. The weights and biases of the first linear layer were specifically analyzed for visualization.

---

## Analysis Methodology

The experimental results are analyzed primarily through visualization and accuracy statistics across the multiple trials.

* **Accuracy Summary:** The distribution of final classification accuracy (number of correctly classified points out of 4) is reported for each model architecture across the 20 runs to assess reliability.
* **Hyperplane Visualization:** For each model in each trial, the decision boundary (hyperplane $w^T x + b = 0$) associated with each neuron in the *first* linear layer is plotted along with the 4 XOR data points. These visualizations are the primary tool used to qualitatively assess whether the learned boundaries intersect or align closely with the XOR points (interpreted as prototypes), as predicted by the hypothesis.
* **ReLU Mirrored Weight Analysis:** For the `XOR_ReLU` model runs, the cosine similarity between the weight vectors of the two neurons in the first layer is calculated to quantitatively check for the emergence of mirrored pairs ($w_1 \approx -w_2$). This provides evidence for or against the hypothesis that ReLU pairs learn to mimic the Abs function in successful solutions.
* **Best Model Selection:** The first model of each type to achieve perfect accuracy (4/4) during the trials is identified and its hyperplane plot is highlighted.

### Rationale for Analysis Approach

The main goal is not simply to achieve high accuracy on XOR (which is expected), but to **visually and qualitatively analyze the geometric solutions learned by the different architectures**. The focus is on examining the placement of the first-layer hyperplanes relative to the data points to see if it supports the prototype intersection hypothesis over a traditional linear separation view. Analyzing results across multiple trials helps understand the consistency of these geometric patterns and the potential for different local minima or failure modes (e.g., broken symmetry in ReLU models).